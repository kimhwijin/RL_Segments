{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd971e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjkim/anaconda3/envs/torchrl/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 100, 1]), torch.Size([5000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataloader import SeqComb\n",
    "train_set = SeqComb.get_SeqComv('onetwo', 'TRAIN')\n",
    "train_set.X.shape, train_set.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1345076f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36.7031)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights = torch.tensor([1/100]).repeat(64, 100)\n",
    "sorted, _ = torch.multinomial(weights, 2, replacement=True).float().sort()\n",
    "start, end = sorted[:, 0], sorted[:, 1]\n",
    "(end-start).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0253302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d19abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-4e3a8062ab09>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pth = torch.load(\"./checkpoints/pred_onetwo_ppo_tcn_cat_nb_0.7,0.3/onetwo_ppo_tcn_cat_nb_0.7,0.3.pth\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints/pred_onetwo_ppo_tcn_cat_nb_0.7,0.3/onetwo_ppo_tcn_cat_nb_0.7,0.3.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pth \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./checkpoints/pred_onetwo_ppo_tcn_cat_nb_0.7,0.3/onetwo_ppo_tcn_cat_nb_0.7,0.3.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/pred_onetwo_ppo_tcn_cat_nb_0.7,0.3/onetwo_ppo_tcn_cat_nb_0.7,0.3.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pth = torch.load(\"./checkpoints/pred_onetwo_ppo_tcn_cat_nb_0.7,0.3/onetwo_ppo_tcn_cat_nb_0.7,0.3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onetwo_ppo_tcn_cat_nb_0.7,0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjkim/RL_TimeSegment/utils/plot.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f\"{exp_dir}/{exp_name}.pth\")\n"
     ]
    }
   ],
   "source": [
    "from utils.plot import result_plots\n",
    "\n",
    "result_plots(\n",
    "    loss='ppo',\n",
    "    backbone='tcn',\n",
    "    weights=[0.7, 0.3],\n",
    "    seg_dist='cat_nb',\n",
    "    dataset='onetwo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Policy, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81be2b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjkim/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from models import Policy, Value\n",
    "policy_module = Policy.init_policy_module(\n",
    "    d_in = 1,\n",
    "    d_model = 128,\n",
    "    d_out = 3,\n",
    "    seq_len = 100,\n",
    "    backbone = 'tcn',\n",
    "    seg_dist = 'cat_nb'\n",
    ")\n",
    "value_module, advantage_module = Value.init_value_module(\n",
    "    d_in = 1,\n",
    "    d_model = 128,\n",
    "    seq_len = 100,\n",
    "    backbone = 'tcn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb374bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0795, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(policy_module.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.objectives import ClipPPOLoss\n",
    "\n",
    "loss_module = ClipPPOLoss(\n",
    "        actor=policy_module,\n",
    "        critic=value_module,\n",
    "        clip_epsilon=0.2,\n",
    "        entropy_bonus=True,\n",
    "        entropy_coef=0.01,\n",
    "        critic_coef=1.0,\n",
    "        loss_critic_type=\"smooth_l1\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e518a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClipPPOLoss(\n",
       "  (actor_network_params): TensorDictParams(params=TensorDict(\n",
       "      fields={\n",
       "          module: TensorDict(\n",
       "              fields={\n",
       "                  0: TensorDict(\n",
       "                      fields={\n",
       "                          module: TensorDict(\n",
       "                              fields={\n",
       "                                  backbone: TensorDict(\n",
       "                                      fields={\n",
       "                                          tcn: TensorDict(\n",
       "                                              fields={\n",
       "                                                  0: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          conv1: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_v: Parameter(shape=torch.Size([128, 2, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          conv2: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          downsample: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight: Parameter(shape=torch.Size([128, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          net: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  0: TensorDict(\n",
       "                                                                      fields={\n",
       "                                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_v: Parameter(shape=torch.Size([128, 2, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                                      batch_size=torch.Size([]),\n",
       "                                                                      device=None,\n",
       "                                                                      is_shared=False),\n",
       "                                                                  4: TensorDict(\n",
       "                                                                      fields={\n",
       "                                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                                      batch_size=torch.Size([]),\n",
       "                                                                      device=None,\n",
       "                                                                      is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False),\n",
       "                                                  1: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          conv1: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          conv2: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          net: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  0: TensorDict(\n",
       "                                                                      fields={\n",
       "                                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                                      batch_size=torch.Size([]),\n",
       "                                                                      device=None,\n",
       "                                                                      is_shared=False),\n",
       "                                                                  4: TensorDict(\n",
       "                                                                      fields={\n",
       "                                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                                      batch_size=torch.Size([]),\n",
       "                                                                      device=None,\n",
       "                                                                      is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False),\n",
       "                                                  2: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          conv1: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          conv2: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False),\n",
       "                                                          net: TensorDict(\n",
       "                                                              fields={\n",
       "                                                                  0: TensorDict(\n",
       "                                                                      fields={\n",
       "                                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                                      batch_size=torch.Size([]),\n",
       "                                                                      device=None,\n",
       "                                                                      is_shared=False),\n",
       "                                                                  4: TensorDict(\n",
       "                                                                      fields={\n",
       "                                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                                      batch_size=torch.Size([]),\n",
       "                                                                      device=None,\n",
       "                                                                      is_shared=False)},\n",
       "                                                              batch_size=torch.Size([]),\n",
       "                                                              device=None,\n",
       "                                                              is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False)},\n",
       "                                      batch_size=torch.Size([]),\n",
       "                                      device=None,\n",
       "                                      is_shared=False),\n",
       "                                  end_proj: TensorDict(\n",
       "                                      fields={\n",
       "                                          bias: Parameter(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                          weight: Parameter(shape=torch.Size([2, 128]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                      batch_size=torch.Size([]),\n",
       "                                      device=None,\n",
       "                                      is_shared=False),\n",
       "                                  start_proj: TensorDict(\n",
       "                                      fields={\n",
       "                                          bias: Parameter(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                          weight: Parameter(shape=torch.Size([100, 128]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                      batch_size=torch.Size([]),\n",
       "                                      device=None,\n",
       "                                      is_shared=False)},\n",
       "                              batch_size=torch.Size([]),\n",
       "                              device=None,\n",
       "                              is_shared=False)},\n",
       "                      batch_size=torch.Size([]),\n",
       "                      device=None,\n",
       "                      is_shared=False)},\n",
       "              batch_size=torch.Size([]),\n",
       "              device=None,\n",
       "              is_shared=False)},\n",
       "      batch_size=torch.Size([]),\n",
       "      device=None,\n",
       "      is_shared=False))\n",
       "  (critic_network_params): TensorDictParams(params=TensorDict(\n",
       "      fields={\n",
       "          module: TensorDict(\n",
       "              fields={\n",
       "                  backbone: TensorDict(\n",
       "                      fields={\n",
       "                          tcn: TensorDict(\n",
       "                              fields={\n",
       "                                  0: TensorDict(\n",
       "                                      fields={\n",
       "                                          conv1: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_v: Parameter(shape=torch.Size([128, 2, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          conv2: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          downsample: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight: Parameter(shape=torch.Size([128, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          net: TensorDict(\n",
       "                                              fields={\n",
       "                                                  0: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_v: Parameter(shape=torch.Size([128, 2, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False),\n",
       "                                                  4: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False)},\n",
       "                                      batch_size=torch.Size([]),\n",
       "                                      device=None,\n",
       "                                      is_shared=False),\n",
       "                                  1: TensorDict(\n",
       "                                      fields={\n",
       "                                          conv1: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          conv2: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          net: TensorDict(\n",
       "                                              fields={\n",
       "                                                  0: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False),\n",
       "                                                  4: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False)},\n",
       "                                      batch_size=torch.Size([]),\n",
       "                                      device=None,\n",
       "                                      is_shared=False),\n",
       "                                  2: TensorDict(\n",
       "                                      fields={\n",
       "                                          conv1: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          conv2: TensorDict(\n",
       "                                              fields={\n",
       "                                                  bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                  weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False),\n",
       "                                          net: TensorDict(\n",
       "                                              fields={\n",
       "                                                  0: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False),\n",
       "                                                  4: TensorDict(\n",
       "                                                      fields={\n",
       "                                                          bias: Parameter(shape=torch.Size([128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_g: Parameter(shape=torch.Size([128, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                                                          weight_v: Parameter(shape=torch.Size([128, 128, 7]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                                                      batch_size=torch.Size([]),\n",
       "                                                      device=None,\n",
       "                                                      is_shared=False)},\n",
       "                                              batch_size=torch.Size([]),\n",
       "                                              device=None,\n",
       "                                              is_shared=False)},\n",
       "                                      batch_size=torch.Size([]),\n",
       "                                      device=None,\n",
       "                                      is_shared=False)},\n",
       "                              batch_size=torch.Size([]),\n",
       "                              device=None,\n",
       "                              is_shared=False)},\n",
       "                      batch_size=torch.Size([]),\n",
       "                      device=None,\n",
       "                      is_shared=False),\n",
       "                  proj: TensorDict(\n",
       "                      fields={\n",
       "                          bias: Parameter(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                          weight: Parameter(shape=torch.Size([1, 128]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                      batch_size=torch.Size([]),\n",
       "                      device=None,\n",
       "                      is_shared=False)},\n",
       "              batch_size=torch.Size([]),\n",
       "              device=None,\n",
       "              is_shared=False)},\n",
       "      batch_size=torch.Size([]),\n",
       "      device=None,\n",
       "      is_shared=False))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa82032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7, 0.3]\n",
      "Pr:pred_Da:onetwo_L:ppo_BcB:tcn_SeDcat_nb_We:0.7,0.3_Tr:blackbox_Ms:seq\n",
      "/home/hjkim/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/home/hjkim/RL_TimeSegment/ppo.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  blackbox_model.load_state_dict(torch.load(f'./blackbox/best_{dataset}_tcn.pth')['model_state'])\n",
      "100%|█████████████████████████████████| 2/2 [00:04<00:00,  2.48s/it, loss=0.972]\n",
      "Epoch : 0\n",
      "\t| Avg Predictor Loss: 1.0882\n",
      "\t| Avg Actor Loss: -0.0102 | Avg Critic Loss: 0.0098 \n",
      "\t| Avg Length: 2.1481 | Avg Reward: 0.5333\n",
      "Best : 0.54\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5368\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.35 | OG  F1: 1.00 | Masked F1: 0.21\n",
      "Epoch : 1\n",
      "\t| Avg Predictor Loss: 1.0757\n",
      "\t| Avg Actor Loss: -0.0054 | Avg Critic Loss: 0.0008 \n",
      "\t| Avg Length: 2.1616 | Avg Reward: 0.5349\n",
      "Best : 0.54\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5355\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.35 | OG  F1: 1.00 | Masked F1: 0.21\n",
      "Epoch : 2\n",
      "\t| Avg Predictor Loss: 1.0680\n",
      "\t| Avg Actor Loss: -0.0174 | Avg Critic Loss: 0.0007 \n",
      "\t| Avg Length: 2.1655 | Avg Reward: 0.5372\n",
      "Best : 0.54\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5369\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.36 | OG  F1: 1.00 | Masked F1: 0.22\n",
      "Epoch : 3\n",
      "\t| Avg Predictor Loss: 1.0612\n",
      "\t| Avg Actor Loss: -0.0170 | Avg Critic Loss: 0.0007 \n",
      "\t| Avg Length: 2.1364 | Avg Reward: 0.5389\n",
      "Best : 0.54\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5372\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.36 | OG  F1: 1.00 | Masked F1: 0.22\n",
      "Epoch : 4\n",
      "\t| Avg Predictor Loss: 1.0583\n",
      "\t| Avg Actor Loss: -0.0071 | Avg Critic Loss: 0.0011 \n",
      "\t| Avg Length: 2.1291 | Avg Reward: 0.5415\n",
      "Best : 0.54\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5375\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.36 | OG  F1: 1.00 | Masked F1: 0.23\n",
      "Pr:pred_Da:onetwo_L:ppo_BcB:tcn_SeDcat_nb_We:0.7,0.3_Tr:blackbox_Ms:seq\n",
      "/home/hjkim/RL_TimeSegment/utils/plot.py:190: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  history = torch.load(f\"{exp_dir}/history.pth\")\n",
      "/home/hjkim/RL_TimeSegment/utils/plot.py:244: UserWarning: Tight layout not applied. tight_layout cannot make axes height small enough to accommodate all axes decorations\n",
      "  fig.tight_layout()\n",
      "Pr:pred_Da:onetwo_L:ppo_BcB:tcn_SeDcat_nb_We:0.7,0.3_Tr:blackbox_Ms:seq\n",
      "/home/hjkim/RL_TimeSegment/utils/plot.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoints = torch.load(f'{exp_dir}/checkpoints.pth')\n",
      "/home/hjkim/RL_TimeSegment/utils/plot.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  blackbox_model.load_state_dict(torch.load(f'./blackbox/best_{dataset}_tcn.pth')['model_state'])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2666c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --dataset onetwo --seg_dist cat_nb --weights 0.7,0.3 --backbone tcn --loss ppo --target_type blackbox --predictor_type blackbox --mask_type seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0058ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr:blackbox_Da:onetwo_L:ppo_BcB:tcn_SeDcat_nb_We:0.7,0.3_Tr:blackbox_Ms:seq\n",
      "Epoch : 0\n",
      "\t| Avg Actor Loss: -0.0053 | Avg Critic Loss: 0.0320 \n",
      "\t| Avg Length: 1.7655 | Avg Reward: 0.5508\n",
      "Best : 0.55\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5507\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.37 | OG  F1: 1.00 | Masked F1: 0.25\n",
      "Epoch : 1\n",
      "\t| Avg Actor Loss: -0.0135 | Avg Critic Loss: 0.0123 \n",
      "\t| Avg Length: 1.7601 | Avg Reward: 0.5561\n",
      "Best : 0.55\n",
      "\t| Avg Length: 1.0000 | Avg Reward: 0.5522\n",
      "\t| OG  Acc: 1.00  | Masked Acc: 0.37 | OG  F1: 1.00 | Masked F1: 0.24\n",
      "Epoch : 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mppo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtcn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseg_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcat_nb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monetwo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblackbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# blackbox, y\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredictor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblackbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# blackbox, predictor\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# seq, zero, normal,\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RL_TimeSegment/ppo.py:158\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(backbone, weights, seg_dist, dataset, target_type, predictor_type, mask_type)\u001b[0m\n\u001b[1;32m    156\u001b[0m logger\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Collect ------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m replay_buffer \u001b[38;5;241m=\u001b[39m \u001b[43mevals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_buffer_with_old_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# torch no grad func\u001b[39;49;00m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy_module\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpolicy_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_module\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43madvantage_module\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43madvantage_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblackbox_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mblackbox_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrollout_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrollout_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreward_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreward_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Predictor Train ------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictor_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RL_TimeSegment/utils/evals.py:139\u001b[0m, in \u001b[0;36mcollect_buffer_with_old_policy\u001b[0;34m(replay_buffer, loader, policy_module, value_module, advantage_module, target_type, blackbox_model, rollout_len, reward_fn, device)\u001b[0m\n\u001b[1;32m    130\u001b[0m     y_target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    131\u001b[0m td \u001b[38;5;241m=\u001b[39m TensorDict(\n\u001b[1;32m    132\u001b[0m     {\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     }, \n\u001b[1;32m    137\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m(B,), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 139\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m value_module(td);\n\u001b[1;32m    141\u001b[0m value_module(td[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/RL_TimeSegment/utils/env.py:32\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(tensordict, policy_module, reward_fn, mode)\u001b[0m\n\u001b[1;32m     30\u001b[0m     reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mreward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# no grad reward func\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# is_done = terminated_fn(x, y, curr_mask, new_mask)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m TensorDict(\n\u001b[1;32m     36\u001b[0m     {\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     device\u001b[38;5;241m=\u001b[39mtensordict\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RL_TimeSegment/rewards/Reward.py:11\u001b[0m, in \u001b[0;36mcompose_reward\u001b[0;34m(reward_fns, weights, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_reward\u001b[39m(reward_fns, weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([reward_fn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m reward_fn \u001b[38;5;129;01min\u001b[39;00m reward_fns], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([weights], dtype\u001b[38;5;241m=\u001b[39mrewards\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mrewards\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     14\u001b[0m     reward \u001b[38;5;241m=\u001b[39m (rewards \u001b[38;5;241m*\u001b[39m weights)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/RL_TimeSegment/rewards/Reward.py:11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_reward\u001b[39m(reward_fns, weights, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mreward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m reward_fn \u001b[38;5;129;01min\u001b[39;00m reward_fns], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([weights], dtype\u001b[38;5;241m=\u001b[39mrewards\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mrewards\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     14\u001b[0m     reward \u001b[38;5;241m=\u001b[39m (rewards \u001b[38;5;241m*\u001b[39m weights)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RL_TimeSegment/rewards/Reward.py:37\u001b[0m, in \u001b[0;36mexp_minus_cross_entropy_reward\u001b[0;34m(x, y, curr_mask, new_mask, predictor, mask_fn)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexp_minus_cross_entropy_reward\u001b[39m(x, y, curr_mask, new_mask, predictor, mask_fn):\n\u001b[0;32m---> 37\u001b[0m     curr_x \u001b[38;5;241m=\u001b[39m \u001b[43mmask_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m mask_fn(x, torch\u001b[38;5;241m.\u001b[39mlogical_or(curr_mask, new_mask))\n\u001b[1;32m     39\u001b[0m     logits \u001b[38;5;241m=\u001b[39m predictor(next_x)\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/RL_TimeSegment/utils/masking.py:27\u001b[0m, in \u001b[0;36mSeqCombMask.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n\u001b[1;32m     26\u001b[0m     B, T, D \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 27\u001b[0m     x_star, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_ts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     x_star \u001b[38;5;241m=\u001b[39m x_star\u001b[38;5;241m.\u001b[39mreshape(B, T, D)\n\u001b[1;32m     29\u001b[0m     x_star \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_star, dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/timesynth/timeseries.py:40\u001b[0m, in \u001b[0;36mTimeSeries.sample\u001b[0;34m(self, time_vector)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Vectorize if possible\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_generator\u001b[38;5;241m.\u001b[39mvectorizable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_generator\u001b[38;5;241m.\u001b[39mvectorizable:\n\u001b[0;32m---> 40\u001b[0m     signals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_generator\u001b[38;5;241m.\u001b[39msample_vectorized(time_vector)\n\u001b[1;32m     42\u001b[0m     samples \u001b[38;5;241m=\u001b[39m signals \u001b[38;5;241m+\u001b[39m errors\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/timesynth/signals/narma.py:105\u001b[0m, in \u001b[0;36mNARMA.sample_vectorized\u001b[0;34m(self, times)\u001b[0m\n\u001b[1;32m    103\u001b[0m end \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, end):\n\u001b[0;32m--> 105\u001b[0m     values[t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Store valus for later retrieval\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m rands[start:]\n",
      "File \u001b[0;32m~/anaconda3/envs/torchrl/lib/python3.8/site-packages/timesynth/signals/narma.py:62\u001b[0m, in \u001b[0;36mNARMA._next_value\u001b[0;34m(self, values, rands, index)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"Internal short-hand method to calculate next value.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Short-hand parameters\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\n\u001b[1;32m     63\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoefficients\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Get value arrays\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ppo\n",
    "ppo.main(\n",
    "    backbone='tcn',\n",
    "    weights=[0.7,0.3],\n",
    "    seg_dist='cat_nb',\n",
    "    dataset='onetwo',\n",
    "    target_type='blackbox', # blackbox, y\n",
    "    predictor_type='blackbox', # blackbox, predictor\n",
    "    mask_type='seq', # seq, zero, normal,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
